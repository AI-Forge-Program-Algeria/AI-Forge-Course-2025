{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFgoJGR-jixW"
      },
      "source": [
        "## 01 - Preparing Data for Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7qJmElZjixc",
        "outputId": "46419e80-d8e2-416c-e43e-27f883c526dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of descriptions : 20\n",
            "\n",
            "Sample course descriptions : ['In this practical, hands-on course, learn how to do data preparation, data munging, data visualization, and predictive analytics. ', 'PHP is the most popular server-side language used to build dynamic websites, and though it is not especially difficult to use, nonprogrammers often find it intimidating. ']\n"
          ]
        }
      ],
      "source": [
        "# Read course descriptions\n",
        "with open(\"Course-Descriptions.txt\", 'r') as fh:\n",
        "    descriptions = fh.read().splitlines()\n",
        "\n",
        "print(\"Number of descriptions :\", len(descriptions))\n",
        "print(\"\\nSample course descriptions :\", descriptions[:2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Setup wordnet for lemmatization\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Custom tokenizer that will perform tokenization, stopword removal and lemmatization\n",
        "def customtokenize(str):\n",
        "    tokens = nltk.word_tokenize(str)\n",
        "    nostop = list(filter(lambda token: token not in stopwords.words('english'), tokens))\n",
        "    lemmatized = [lemmatizer.lemmatize(word) for word in nostop]\n",
        "    return lemmatized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppQH0kQUj66-",
        "outputId": "71921909-d5d0-4233-a092-97b419e0ba92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate TFIDF matrix\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=customtokenize)\n",
        "tfidf = vectorizer.fit_transform(descriptions)\n",
        "\n",
        "print(\"\\nSample feature names identified : \", vectorizer.get_feature_names_out()[:25])\n",
        "print(\"\\nSize of TFIDF matrix : \",tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnvtDLKZkEDJ",
        "outputId": "a1f31fa1-a02a-46f7-cb1e-bd696218ed38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample feature names identified :  [\"'ll\" \"'re\" \"'s\" '(' ')' ',' '.' '?' 'actively' 'adopting' 'amazon'\n",
            " 'analysis' 'analytics' 'application' 'applied' 'architect' 'architecture'\n",
            " 'around' 'aspect' 'associate' 'aws' 'basic' 'become' 'begin' 'big']\n",
            "\n",
            "Size of TFIDF matrix :  (20, 238)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44KizS0Pjixg"
      },
      "source": [
        "## 02 - Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c1cICEdjixh"
      },
      "outputs": [],
      "source": [
        "# Loading the pre-built classifications for training\n",
        "with open(\"Course-Classification.txt\", 'r') as fh:\n",
        "    classifications = fh.read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Labels and integer classes\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(classifications)\n",
        "print(\"Classes found : \", le.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yGE47UDkhGu",
        "outputId": "c2696e20-dbbd-4793-8f7c-36d3e2f6cc16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes found :  ['Cloud-Computing' 'Data-Science' 'Programming']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert classes to integers for use with ML\n",
        "int_classes = le.transform(classifications)\n",
        "print(\"\\nClasses converted to integers :\", int_classes)\n",
        "print(\"\\nActual classes :\", classifications)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPRx7jPrkjER",
        "outputId": "9468e6ab-2e72-40d7-c408-bd97a8afa3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classes converted to integers : [1 2 2 0 1 2 1 2 0 1 1 2 2 0 2 0 0 0 2 2]\n",
            "\n",
            "Actual classes : ['Data-Science', 'Programming', 'Programming', 'Cloud-Computing', 'Data-Science', 'Programming', 'Data-Science', 'Programming', 'Cloud-Computing', 'Data-Science', 'Data-Science', 'Programming', 'Programming', 'Cloud-Computing', 'Programming', 'Cloud-Computing', 'Cloud-Computing', 'Cloud-Computing', 'Programming', 'Programming']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Split as training and testing sets\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(tfidf, int_classes,random_state=0)\n",
        "\n",
        "# Build the model\n",
        "classifier= MultinomialNB().fit(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "14Om1RCBklG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CinZ2Od4jixi"
      },
      "source": [
        "## 03 - Running Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayuLrAI2jixi",
        "outputId": "8d758544-14f5-45f7-9b0f-d7ba1a013d38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20, 238), (15, 238), (5, 238), (15,))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "tfidf.shape, xtrain.shape, xtest.shape, ytrain.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUjvja7xjixi",
        "outputId": "784aa187-b7d0-4e6d-bc0f-796e3dc97a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing with Test Data :\n",
            "------------------------\n",
            "Confusion Matrix : \n",
            "[[1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 2]]\n",
            "\n",
            "Prediction Accuracy :  0.6\n",
            "\n",
            "Testing with Full Corpus :\n",
            "--------------------------\n",
            "Confusion Matrix : \n",
            "[[6 0 0]\n",
            " [0 4 1]\n",
            " [1 0 8]]\n",
            "\n",
            "Prediction Accuracy :  0.9\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"Testing with Test Data :\\n------------------------\")\n",
        "# Predict on test data\n",
        "predictions=classifier.predict(xtest)\n",
        "print(\"Confusion Matrix : \")\n",
        "print(metrics.confusion_matrix(ytest, predictions))\n",
        "print(\"\\nPrediction Accuracy : \",  \\\n",
        "      metrics.accuracy_score(ytest, predictions) )\n",
        "\n",
        "print(\"\\nTesting with Full Corpus :\\n--------------------------\")\n",
        "\n",
        "# Predict on entire corpus data\n",
        "predictions=classifier.predict(tfidf)\n",
        "print(\"Confusion Matrix : \")\n",
        "print(metrics.confusion_matrix(int_classes, predictions))\n",
        "print(\"\\nPrediction Accuracy : \",  \\\n",
        "      metrics.accuracy_score(int_classes, predictions) )\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}